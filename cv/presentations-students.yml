- title: "Mesh refinement in the 3D inversion of potential-field data through the planting method"
  authors: [GabrielChagas, Me]
  year: 2025
  conference: SBGf Conference Rio‚Äô25
  link: https://sbgf.org.br/mysbgf/eventos/expanded_abstracts/19th_CISBGf/RZM0LGPM4A.pdf
  abstract: |
    Geophysical inversions are essential for interpreting geological structures through indirect observations, like potential field data. The planting method is a computationally efficient inversion algorithm that grows a solution iteratively from ‚Äúseed‚Äù elements within a discretized 3D mesh of rectangular prisms. The original software implementation has been updated and the method has been expanded to include a new mesh refinement strategy. Current results demonstrate that the mesh refinement is successful at recovering complex geometries from a single starting seed. The influence of mesh size on the inversion accuracy and the calibration of critical parameters (e.g., regularization and normalization factors) require further investigation

- title: "Towards an open source tool for the magnetic microscopy community"
  authors: [Yago, Me]
  year: 2025
  conference: SBGf Conference Rio‚Äô25
  link: https://sbgf.org.br/mysbgf/eventos/expanded_abstracts/19th_CISBGf/9YNJ950MY8.pdf
  abstract: |
    Paleomagnetism relies on magnetic signals preserved in minerals to reconstruct Earth‚Äôs geodynamic history, yet traditional techniques average magnetization across bulk rock samples. Magnetic microscopy ennables measurement of magnetic fields from individual mineral grains. To fully exploit this potential, new computational tools are needed to process the massive datasets generated by this technique. This project introduces Magali, an open-source Python software designed to handle and interpret magnetic microscopy data with a focus on paleomagnetic applications. Magali will implement state-of-the-art methods, including automatic dipole inversion based on Euler deconvolution and dipolar modeling, as well as QDM-specific processing tools. Developed under the Fatiando a Terra project, Magali will be released with thorough documentation and community-focused outreach to support adoption and collaborative development. By providing robust and extensible software, this project aims to make magnetic microscopy a practical and widely used method for determining paleomagnetic directions and intensities.

- title: "Preliminary Results of Integrating Airborne Geophysical Datasets Using Equivalent Sources on the Sphere"
  authors: [Arthur, Me]
  year: 2025
  conference: SBGf Conference Rio‚Äô25
  link: https://sbgf.org.br/mysbgf/eventos/expanded_abstracts/19th_CISBGf/BV8GKPJY7K.pdf
  abstract: |
    Geoscientists are increasingly adopting the equivalent source method to process and interpolate magnetic data, particularly in airborne geophysical surveys. However, conventional Cartesian-based approaches face significant limitations when applied to regional and global scales due to the Earth‚Äôs curvature, which complicates data interpolation and integration. This work adapts the magnetic equivalent source method to spherical coordinates. To account for the geometric differences between Cartesian and spherical systems, we introduce modifications to the mathematical formulations. We incorporate the gradient-boosting technique to tackle computational efficiency in datasets with millions of observations. We evaluate the performance of the method through synthetic data tests, identifying conditions in which it can struggle, such as variations in data density and geological complexity. The adapted method will be integrated into open-source software, broadening its accessibility and impact.

- title: "Integration of Terrestrial and Satellite Gravity Data for Crustal Structure Investigation"
  authors: [Eros, Alessandra, Me, Tiago]
  year: 2025
  conference: SBGf Conference Rio‚Äô25
  link: https://sbgf.org.br/mysbgf/eventos/expanded_abstracts/19th_CISBGf/MR0ALNQ5ZW.pdf
  abstract: |
    The integration of terrestrial and satellite gravity data is a relevant methodological strategy to overcome the individual limitations of each dataset: while terrestrial data offer high resolution and capture local variations, satellite data provide broad coverage and global consistency, yet resolve only low-frequency components. This work proposes an integrated approach to interpolate and combine both datasets, aiming to generate continuous gravity grids suitable for crustal geophysical modeling. The methodology consists of interpolating, via the equivalent sources method, the differences between surface gravity observations and the values predicted at the same points by satellite models. The interpolation parameters, such as source depth and damping, are automatically selected using k-fold cross-validation. The final grid is obtained by recombining these differences with the regular satellite-derived grid at constant altitude. Normal gravity is computed based on the GRS80 ellipsoid, and gravity disturbance is used as the reference field for Bouguer and isostatic corrections, both implemented through direct modeling with prisms. Topography and geological layers are discretized on regular meshes to enable spectral and spatially consistent corrections. The proposed technique yields a high-resolution, harmonic, physically consistent, and statistically validated interpolated model. The interpolation of differences ensures spectral compatibility between datasets, while prism-based modeling enables the application of gravity corrections even in geologically complex areas. Its application in a case study over the Southern Mantiqueira Province demonstrated its effectiveness in integrating heterogeneous data and recovering crustal features hidden beneath sedimentary cover. The results indicate that the approach is robust and replicable, and can be applied to other regions and for various structural investigation purposes.

- title: "Integra√ß√£o geof√≠sica e geol√≥gica na Prov√≠ncia Mantiqueira Meridional"
  authors: [Eros, Alessandra, Me, Tiago, Luizemara]
  year: 2025
  conference: XIII Simp√≥sio Sul-Brasileiro de Geologia
  link: https://www.sbgeo.org.br/anais_digitalizados/Anais_Geomine_SBG_2025.pdf
  abstract: |
    O presente trabalho tem como objetivo aplicar o m√©todo gravim√©trico para delimitar os terrenos tectono-estratigr√°ficos da Prov√≠ncia Mantiqueira Meridional. Essa prov√≠ncia geol√≥gica, formada durante a Orog√™nese Brasiliana, √© subdividida nos segmentos setentrional, central e meridional, cada um caracterizado por cintur√µes orog√™nicos distintos. O estudo busca aprimorar a compreens√£o da continuidade lateral das estruturas e dos terrenos ocultos por sedimentos, utilizando dados gravim√©tricos para integrar a Prov√≠ncia Mantiqueira ao embasamento da Bacia do Paran√°. Os terrenos tectono- estratigr√°ficos s√£o conjuntos de rochas delimitados por falhas, que se diferenciam por suas estratigrafias e contextos geol√≥gicos. O Cintur√£o Dom Feliciano √© composto pelos terrenos Nico P√©rez/Taquaremb√≥, S√£o Gabriel, Tijucas, Punta del Este e pelo Bat√≥lito Florian√≥polis- Pelotas-Aigu√°. Devido √† cobertura sedimentar, grande parte desses terrenos permanece pouco definida, exigindo o uso de m√©todos indiretos, como a gravimetria, para sua investiga√ß√£o. A pesquisa utiliza dados gravim√©tricos obtidos por institui√ß√µes como Petrobras, ANP, IBGE e Observat√≥rio Nacional, organizados pelo Banco Nacional de Dados Gravim√©tricos (BNDG). Para o processamento e a an√°lise, foram empregadas ferramentas computacionais baseadas em Python, como as bibliotecas Boule e Harmonica. O dist√∫rbio da gravidade, calculado na superf√≠cie terrestre, foi utilizado em substitui√ß√£o √† anomalia de Ar Livre. A corre√ß√£o de Bouguer, tradicionalmente aplicada √†s anomalias de Ar Livre, foi empregada no dist√∫rbio da gravidade, resultando no chamado Dist√∫rbio de Bouguer. O gradeamento dos dados foi realizado por meio do m√©todo das fontes equivalentes. Filtros de realce foram aplicados aos dados processados para destacar estruturas geol√≥gicas espec√≠ficas, como bordas de contatos litol√≥gicos e anomalias de densidade associadas a processos intrusivos e metam√≥rficos. Para a interpreta√ß√£o dos dados, os resultados geof√≠sicos foram comparados com mapas geol√≥gicos regionais do Servi√ßo Geol√≥gico do Brasil (SGB/CPRM), visando √† integra√ß√£o entre informa√ß√µes geof√≠sicas e geol√≥gicas. Como resultado, foi elaborado um arcabou√ßo geof√≠sico-estrutural integrado preliminar, que permitiu identificar as principais fei√ß√µes estruturais da Prov√≠ncia Mantiqueira Meridional, contribuindo para a compreens√£o da evolu√ß√£o crustal e da geodin√¢mica regional.


- title: "Mitigation of Outliers in Gravity Interpolation Using Weighted Equivalent Sources"
  authors: [Eros, Me, Alessandra, Luizemara]
  year: 2025
  conference: X Simp√≥sio de Quantifica√ß√£o em Geoci√™ncias ‚Äì GEOQUANTI
  link: https://www.geoquantificacao.com.br/assets/files/ANAIS-DERESUMO-XGEOQUANTI-2025.pdf
  abstract: |
    In a terrestrial gravity database, each data unit results from a field measurement conducted by an individual. Given the manual and labor-intensive nature of data acquisition, a high variability in measurement accuracy is assumed. Since these are geospatial data, filtering out discrepant values is a challenging process, as an anomalous value must be evaluated in relation to its neighbors but cannot be directly compared to areas with different geological contexts within the study region. The remaining alternative is to manually identify outlier points, a process analogous to the selective screening of impurities in a granular dataset. However, in large databases, the manual method, besides being laborious, does not ensure the effective removal of all anomalous values relative to their neighbors. Typically, the last outliers persist until the final processing stages, being identified only by the "spike" effect they produce in the interpolated grid. Ideally, a data analysis method should not only be automated but also allow control and traceability of the modifications, eliminating the subjectivity of manual selection. This study proposes an iterative weighting technique based on the equivalent source method to mitigate the effects of outliers in gravity data interpolation. The developed code implements an interpolation method based on equivalent sources (EquivalentSourcesGB), designed to reduce the impact of significantly discrepant data points. The function starts by receiving the coordinates and observed values of the data, along with parameters such as source depth, damping, and the maximum number of iterations. The process iteratively refines the interpolation by adjusting the estimated weights in each cycle. Based on misfit values‚Äîthe difference between observed and predicted values‚Äîthe weights are recalculated to minimize the influence of outlier points. Two methods are available for weight adjustment: the inverse of the absolute residual value or the inverse of its square. To prevent division by zero, only residuals above a defined tolerance are considered. In each iteration, the function also evaluates the stability of the process using a logarithmic analysis of the standard deviations of the residuals. If the derivative of the fitted logarithmic curve falls below a predefined threshold, the process is deemed stable, and the iterations are terminated. The loop stops when stability is achieved or when the maximum number of iterations is reached. At the end, the function returns the final adjusted weight vector, reflecting the reduced influence of outliers on the interpolation. This approach preserves most of the data while mitigating the negative effects of outliers, making the process more robust and reliable. Statistical data processing is an essential step in any scientific endeavor. In the case of geophysical data, an effective approach must consider the First Law of Geography: "Everything is related to everything else, but near things are more related than distant things." The method presented in this study incorporates this perspective by handling outliers in an iterative and quantitative manner using the equivalent source method. The technique was tested with real gravity data from the south-central region of Brazil and demonstrated effectiveness in improving the quality of the interpolated grid.

- title: "Geometric Algorithm for Optimized Grid Spacing Determination in Fractal Dimension Analyses"
  authors: [Eros, Saulo, Me, Alessandra, Tiago]
  year: 2025
  conference: X Simp√≥sio de Quantifica√ß√£o em Geoci√™ncias ‚Äì GEOQUANTI
  link: https://www.geoquantificacao.com.br/assets/files/ANAIS-DERESUMO-XGEOQUANTI-2025.pdf
  abstract: |
    This study presents a method to define the ideal spatial resolution of the regular grid in the interpolation of irregularly distributed gravity data. In sparse gravity data, the heterogeneous spatial distribution of points can exacerbate interpolation errors if the grid spacing is not well-defined. Traditional methods rely on arbitrary choices or manual analyses, whereas the approach presented here automates the selection of the optimal resolution. Fractal dimension is a widely used tool to describe irregular and self-similar structures, proving useful in characterizing the density and homogeneity of gravity data networks. Based on the concepts described by Keating (1992) in "Determination of the Optimum Gridding Interval of a Gravity Data Set", the method applied here utilizes fractal dimension analysis via the Box-Counting geometric algorithm to identify the grid resolution that minimizes the distortion of interpolated data. The grid spacing (box size), ùúπ, is related to the number of filled boxes, N(ùúπ), by N(ùúπ) ‚àù ùúπ‚Åª·¥∞, where D is the fractal dimension. The optimized grid interval is identified at the point where the distribution of points ceases to exhibit fractal characteristics and assumes a Euclidean behavior. This transition occurs when the slope of the log(ùúπ)-log(N(ùúπ)) graph reaches ‚àí2. The method was implemented in Python, using computational tools such as KD trees (k-d tree) for proximity calculations, log-log transformations for scale analysis, and numerical derivatives for inflection point identification. The workflow follows three main steps: computing box sizes, counting the number of boxes filled with at least one gravity station, and identifying the inflection point in the log(ùúπ)-log(N(ùúπ)) graph. The box sizes are defined based on the planimetric distances between points and their nearest neighbors. These distances are calculated, compiled, and divided into percentiles (quartiles or deciles). Each interval is then subdivided into smaller sizes, with the number of subdivisions being proportional to the square root of the interval‚Äôs range. The generated intervals are finally concatenated to form the final list of box sizes. For each value in this list, the space is divided, and the number of filled boxes is counted. In the inflection point identification step in the log-log graph, the values of ùúπ and N(ùúπ) are transformed into a logarithmic scale. Next, the slope between consecutive points on the curve is computed using the numerical derivative. The inflection point is defined as the first point where the curve's slope reaches or falls below the ‚àí2 threshold. Finally, the function returns the ùúπ value corresponding to the inflection point, which represents the optimized grid interval. The method was tested on terrestrial gravity data from the south-central region of Brazil and on synthetic data. The results demonstrated its effectiveness, yielding consistent values for the grid interval, such as the 13,664 m value calculated for the south-central Brazil gravity network (Figure 1). However, some limitations were observed. When following an increasing sequence of box sizes, the inflection point tends to be reached earlier when a larger number of variations is tested. However, if the total number of variations is too high, the log-log graph may exhibit abrupt deviations at specific points, making the precise identification of the inflection point more challenging.

- title: "Modelagem prism√°tica estratificada com backstripping aplicada √† corre√ß√£o gravim√©trica na Bacia do Paran√°"
  authors: [Eros, Me, Alessandra, Tiago]
  year: 2024
  conference: I Simp√≥sio de Bacias Sedimentares
  link: https://sbgeo.org.br/anais_digitalizados/1SBS_Anais.pdf
  abstract: |
    Este trabalho apresenta uma metodologia integrada para modelagem gravim√©trica na Bacia do Paran√°, com foco na discretiza√ß√£o tridimensional de unidades geol√≥gicas e na aplica√ß√£o do m√©todo de backstripping. A proposta visa refinar a representa√ß√£o das massas subsuperficiais por meio de prismas retangulares com densidade diferencial, corrigindo limita√ß√µes da abordagem topogr√°fica tradicional que assume densidade constante acima da superf√≠cie de refer√™ncia. A espessura total dos sedimentos √© obtida por interpola√ß√£o de dados vetoriais provenientes do mapa tect√¥nico da Am√©rica do Sul, do modelo Crust 1.0 e do modelo GlobSed v3. Ap√≥s reproje√ß√£o, recorte espacial e fus√£o controlada por dist√¢ncia m√≠nima, os dados s√£o interpolados sobre uma malha regular por meio de splines. Camadas espec√≠ficas s√£o posteriormente isoladas e refinadas. A unidade magm√°tica Serra Geral √© caracterizada com base em dois conjuntos principais: curvas is√≥pacas (espessura) e curvas de contorno estrutural da superf√≠cie superior do Aqu√≠fero Guarani, utilizadas como base do basalto. As grades geradas passam por ajustes condicionais que imp√µem coer√™ncia estratigr√°fica com os limites do embasamento e da topografia. As espessuras das principais unidades ‚Äî sedimentos totais, basaltos, cobertura acima dos basaltos e sedimentos abaixo dos basaltos ‚Äî s√£o calculadas a partir da diferen√ßa entre superf√≠cies interpoladas, com truncamento de valores negativos. Em seguida, essas camadas s√£o convertidas em modelos prism√°ticos tridimensionais, nos quais a densidade diferencial √© atribu√≠da ponto a ponto apenas quando h√° espessura positiva. Cada conjunto representa, assim, uma camada de corre√ß√£o gravitacional que pode ser somada ou subtra√≠da do campo de Bouguer, possibilitando uma recupera√ß√£o mais fiel da assinatura geof√≠sica do embasamento. A discretiza√ß√£o √© realizada com aux√≠lio da biblioteca Harmonica, gerando modelos em formato NetCDF compat√≠veis com ferramentas de processamento geof√≠sico. O pipeline, desenvolvido inteiramente em Python, √© automatizado e reprodut√≠vel, permitindo an√°lises multiescalares com vers√µes de alta e baixa frequ√™ncia espectral. A metodologia demonstra especial efic√°cia em contextos como o da Bacia do Paran√°, onde a presen√ßa da unidade m√°fica Serra Geral imp√µe contrastes densit√°rios significativos. Ao integrar interpola√ß√£o geol√≥gica, ajustes estruturais condicionais e modelagem prism√°tica com backstripping, o fluxo proposto fornece uma base robusta para an√°lises gravim√©tricas refinadas, contribuindo para a constru√ß√£o de modelos crustais mais consistentes e geologicamente embasados
